# -*- coding: utf-8 -*-
"""FinalProject_Smart-Traffic-Violation-Pattern-Detector-Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Dh4dG8Q963hMUQ7Adb2hBJp1p-UxHOJa

##**Smart Traffic Violation Pattern Detector Project**
This project analyzes traffic violation data using Python, NumPy, Pandas, Matplotlib, and Seaborn to identify trends, hotspots, and behavioral patterns in traffic violations.

#Step 1 — Import Required Libraries
"""

import os
import zipfile
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

"""##Step 2 — Load the CSV Data"""

#Loading and exploring the dataset
df=pd.read_csv('/content/Indian_Traffic_Violations.csv')
df.head() #showing first five rows.
df.tail() #showing last five rows.

"""##Step 3 — Understand Dataset Structure"""

df.info() #shows column names, data types and missing values.

df.describe() #shows summary statistics of numerical columns.

df.isnull().sum() #shows count of missing (null) values.

#very important to check missing & Duplicate data: missing values can cause incorrect calculations or error in data models because the dataset become incomplete.
#Similarly, duplicate data can make results biased like counting the same person or transaction twice.
#This gives misleading insights and affects the accuracy of our analysis.

df.duplicated().sum() #shows count of duplicate rows.

df.shape #shows number of rows and columns.

df.dtypes #shows data types of each column.

df['Fine_Amount'].describe()

"""##Step 4 — Data Cleaning and Preprocessing"""

# Drop duplicates
df.drop_duplicates(inplace=True)

# Handle missing values (example: fill NAs or drop rows)
df.dropna(subset=['Date', 'Time'], inplace=True)

# Convert date and time columns if available
df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
if 'Time' in df.columns:
    df['Time'] = pd.to_datetime(df['Time'], errors='coerce').dt.time

# Extract useful time-based features
df['Day'] = df['Date'].dt.day_name()
df['Month'] = df['Date'].dt.month_name()
df['Hour'] = pd.to_datetime(df['Date']).dt.hour

print("Data cleaned and new columns added!")
df.head()

"""##Step 5 — Exploratory Data Analysis (EDA)"""

# Total violations per day
plt.figure(figsize=(12,5))  #create a new blank chart area of size 10,5. it define width and height of the bar graph.
df['Day'].value_counts().plot(kind='bar', color='skyblue') #Takes the day column from the dataframe(df).Count how many times each day.
                                                           #Plots those counts as a bar chart.Each bar represents one day of the week.
                                                           #The height of each bar=number of violations that day.color skyblue makes bars visually appealing.
plt.title('Violations by Day of Week') #Add a title to the chart- helps understand what the visualization represents.
plt.xlabel('Day of Week')   #Day of week like Mon-sun.
plt.ylabel('Count')         #count number of violations.
plt.show()                  #display the final char.

# Violations by Month
plt.figure(figsize=(12,5))
df['Month'].value_counts().plot(kind='bar', color='orange')
plt.title('Violations by Month')
plt.xlabel('Month')
plt.ylabel('Count')
plt.show()

"""##Step 6 — Violation Type Analysis"""

# Analysis most common violation type.
plt.figure(figsize=(12,5))
sns.countplot(
    y=df['Violation_Type'],
    order=df['Violation_Type'].value_counts().index,
    palette='coolwarm'
)
plt.title("Most Common Violation Type Analysis")
plt.xlabel('count')
plt.ylabel('Violation Type')
plt.tight_layout() #prevent label cutoffs
plt.show()

#Analysis Fine Paid vs Vehicle Type(pie chart)
fine_data = df.groupby('Vehicle_Type')['Fine_Amount'].sum() #Groups your dataset based on each Vehicle_Type(car,bike,etc.),select only fine_Amount column,Adds up all fine amount for each vehicle type.
plt.figure(figsize=(8, 8))   #sets the overall canvas size of the graph width,height inches.
plt.pie(                     #Starts the pie chart.
    fine_data.values,        #The actual numbers(fine totals)which will form the slices.
    labels=fine_data.index,  #Labelsnfor each slice(the vehicle types)
    autopct='%1.1f%%',       #shows percentages on each slice.(1.1f one decimal place(ex:17.3%))
    startangle=90            #Rotates the pie chart starting point by 90 degree for better visual alignment.
)
plt.title("Fine Paid vs Vehicle Type", fontsize=18) #increases text size for better readability.
plt.axis('equal')            #Maintains equal scaling on x and y axis.
plt.show()                   #show the chart visually.

# Analysis Average fine per location(line chart)
fine_location = df.groupby('Location')['Fine_Amount'].mean().reset_index()

plt.figure(figsize=(10,5))      #set the size of the graph width and height.
plt.plot(                       #plot the line graph,x-axis location,y-axis Fine Amount.
    fine_location['Location'],
    fine_location['Fine_Amount'],
    marker='o'#shows a dot at each point,making each locations value visible.
)
plt.title("Average Fine Amount vs Location")#add title and label for clearity.
plt.xlabel("Location")
plt.ylabel("Average Fine Amount")
plt.xticks(rotation=45)#Rotate location names to avoid overlap.
plt.grid(True) #Add gridline for easy comparison.
plt.tight_layout()#Adjust spacing automatically.adjust layout,labels and title do not overlap.
plt.show()  #Display graph.

#check if column exists.
#df.columns: lists all the columns names in your dataframe.
if 'Violation_Type' in df.columns:  #Return ture if this columns is present.
    plt.figure(figsize=(12,5))
    sns.countplot(y='Violation_Type', data=df, order=df['Violation_Type'].value_counts().index[:5],palette='coolwarm')  #countplot() automaticallycounts the number of occurrances of each category.
                                                                                                      #plot violation types on the y axis. each horizontal bar represents one type of traffic violations.
                                                                                                      #data=df using that our data is coming from the dataframe name df.
                                                                                                      #order=df['Violation_Type'].value_counts() Using because counts how many times each type appears.
                                                                                                      #.index[:5] using select the top 10 most common type.sorted by frequency.
    plt.title('Top 5 Violation Types')
    plt.xlabel('Count') #showing the number of violations in x-axis.
    plt.ylabel('Violation Type')#showing the violation type categories in y-axis.
    plt.show() # display the final visualizations.

#Total no of records
total_records = len(df)
#count how many verticles recorded speed greater than the speed limit
overspeed_count = (df['Recorded_Speed'] > df['Speed_Limit']).sum()

#Calculate Percentage of overspeeding
overspeed_percentage = (overspeed_count / total_records) * 100
#display result
print("Total Record:", total_records)
print("Overspeeding Record:", overspeed_count)
print("Overspeeding Percentage: {:.2f}%".format(overspeed_percentage))

# Filter only rainy-day records
rainy_df = df[df['Weather_Condition'] == 'Rainy']

# Total records in rainy weather
total_rainy = len(rainy_df)

# Count of ceiling violations in rainy weather
rainy_violations = (rainy_df['Recorded_Speed'] > rainy_df['Speed_Limit']).sum()

# Proportion (percentage)
rainy_violation_percentage = (rainy_violations / total_rainy) * 100

print("Total Rainy-Day Records:", total_rainy)
print("Ceiling Violations on Rainy Days:", rainy_violations)
print("Proportion of Ceiling Violations: {:.2f}%".format(rainy_violation_percentage))

#Weather condition Impact on violations
plt.figure(figsize=(12,6))
sns.countplot(
    y='Weather_Condition',
    data=df,
    order=df['Weather_Condition'].value_counts().index,
    palette='magma'
)
plt.title("Violation count by Weather Condition")
plt.xlabel('count')
plt.ylabel('Weather Condition')
plt.tight_layout()
plt.show()

#bar chart: Distribution of payment method
plt.figure(figsize=(8,5))
payment_counts = df['Payment_Method'].value_counts()
sns.barplot(x=payment_counts.index, y = payment_counts.values, palette = 'coolwarm')

plt.title('Distribution of payment method')
plt.xlabel('payment method')
plt.ylabel('number of payments')
plt.show()

"""##Step 7 — Time-based Violation Pattern Detection"""

# Violation trends by hour of day
if 'Hour' in df.columns:
    plt.figure(figsize=(12,5))
    sns.countplot(x='Hour', data=df, color='salmon')
    plt.title('Traffic Violations by Hour of Day')
    plt.xlabel('Hour')
    plt.ylabel('Count')
    plt.show()
# Heatmap: Violations by Day vs Hour
if 'Day' in df.columns and 'Hour' in df.columns:
    pivot = df.pivot_table(index='Day', columns='Hour', aggfunc='size', fill_value=0)
    plt.figure(figsize=(12,6))
    sns.heatmap(pivot, cmap='YlOrBr')
    plt.title('Heatmap: Violations by Day and Hour')
    plt.show()

"""##Step 8 — Hotspot Detection (Top Locations)"""

#Top 5 Violation Hotspots
if 'Location' in df.columns:
    top_locations = df['Location'].value_counts().head(5)
    plt.figure(figsize=(12,5))
    sns.barplot(x=top_locations.values, y=top_locations.index, palette='magma')
    plt.title('Top 5 Violation Hotspots')
    plt.xlabel('Number of Violations')
    plt.ylabel('Location')
    plt.show()

"""##Step 9 — Summary Insights"""

print("Total Violations Recorded:", len(df))
if 'Violation_Type' in df.columns:
    print("Most Common Violation Type:", df['Violation_Type'].mode()[0])
if 'Location' in df.columns:
    print("Top Hotspot Location:", df['Location'].mode()[0])
if 'Day' in df.columns:
    print("Day with Most Violations:", df['Day'].mode()[0])

"""##Step 10 — Conclusion

This project highlights the transformative power of data science in uncovering meaningful insights from Smart Traffic violation pattern detector data. By leveraging visualization and analytical tools, we transformed raw information into actionable intelligence for safer and smarter traffic management.

Key Takeaways:

Temporal analysis (by weekday and hour) unveils distinct behavioral patterns among drivers.

Geospatial visualization pinpoints high-risk zones, helping prioritize enforcement efforts.

The insights generated can guide policymakers and authorities to design more effective road safety strategies and awareness initiatives.

Next Steps:

Incorporate predictive modeling to forecast potential violation spikes.

Integrate external datasets such as weather, holidays, and events for deeper contextual insights.

Deploy interactive dashboards using Streamlit for real-time monitoring and decision-making.
"""